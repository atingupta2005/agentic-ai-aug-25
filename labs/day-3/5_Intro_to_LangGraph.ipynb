{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Introduction to LangGraph - Building Your First Agentic Graph\n",
    "\n",
    "This lab introduces **LangGraph**, a library from the creators of LangChain for building robust, stateful agentic applications. LangGraph allows you to define agent workflows as graphs, where each node is a step in the process and edges define the flow of control. This is particularly useful for creating complex agents that can loop, branch, and call tools in sophisticated ways.\n",
    "\n",
    "We will learn the five core steps of building a LangGraph application:\n",
    "1.  **Define the State**: Create an object that will hold the application's state as it moves through the graph.\n",
    "2.  **Create the Graph Builder**: Initialize the graph with the state object.\n",
    "3.  **Add Nodes**: Define the functions that will perform the work at each step.\n",
    "4.  **Add Edges**: Connect the nodes to define the workflow.\n",
    "5.  **Compile the Graph**: Create the final, runnable application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "\n",
    "# Core LangGraph components\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# For building the chatbot UI\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "\n",
    "# For defining state and interacting with LLMs\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Building a Graph with Simple Python (No LLM)\n",
    "\n",
    "To understand the core mechanics of LangGraph, we'll first build a graph that doesn't involve any AI. This will help isolate the concepts of state, nodes, and edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Define the State Object\n",
    "\n",
    "The `State` is a central concept in LangGraph. It's a Python object that holds all the data that needs to be passed between the nodes in our graph. For a chatbot, this is typically the list of messages in the conversation.\n",
    "\n",
    "We use `Annotated` and `add_messages` to tell LangGraph how to update the `messages` field. `add_messages` is a built-in function (a \"reducer\") that correctly appends new messages to the existing list, maintaining the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The State class defines the structure of our application's state.\n",
    "# Here, it contains a single field, `messages`.\n",
    "class SimpleState(BaseModel):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create the Graph Builder\n",
    "\n",
    "We initialize a `StateGraph` and pass it our state definition. This builder object is what we'll use to construct our workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(SimpleState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Add a Node\n",
    "\n",
    "A node is a function that performs an action. It receives the current state of the graph as input and should return a new state object with any updates. Here, our node will generate a random, silly phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some fun constants for our simple node\n",
    "nouns = [\"Cabbages\", \"Unicorns\", \"Toasters\", \"Penguins\", \"Bananas\"]\n",
    "adjectives = [\"outrageous\", \"smelly\", \"pedantic\", \"existential\", \"moody\"]\n",
    "\n",
    "def silly_node(state: SimpleState) -> SimpleState:\n",
    "    \"\"\"A simple function that acts as a node in our graph.\"\"\"\n",
    "    # This node ignores the input state and just generates a new message.\n",
    "    reply = f\"{random.choice(nouns)} are {random.choice(adjectives)}.\"\n",
    "    # It returns a new State object with the assistant's reply.\n",
    "    return SimpleState(messages=[{\"role\": \"assistant\", \"content\": reply}])\n",
    "\n",
    "# We add the node to our graph builder with a unique name.\n",
    "graph_builder.add_node(\"silly_node\", silly_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Add Edges\n",
    "\n",
    "Edges define the path of execution. We need to tell the graph where to start and where to go after each node. `START` and `END` are special keywords.\n",
    "- The first edge connects the `START` of the graph to our `silly_node`.\n",
    "- The second edge connects `silly_node` to the `END`, meaning the graph will terminate after this node runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"silly_node\")\n",
    "graph_builder.add_edge(\"silly_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Compile the Graph\n",
    "\n",
    "This finalizes the graph and makes it a runnable object. We can also visualize the structure we've just built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = graph_builder.compile()\n",
    "\n",
    "# Display a visual representation of the graph.\n",
    "display(Image(simple_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our simple graph.\n",
    "initial_state = SimpleState(messages=[{\"role\": \"user\", \"content\": \"Hello!\"}])\n",
    "result = simple_graph.invoke(initial_state)\n",
    "\n",
    "print(result['messages'][-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Building a Chatbot with an LLM\n",
    "\n",
    "Now that we understand the 5-step process, let's replace our simple Python node with a node that calls an LLM. The structure of the graph will be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 & 2: Define State and initialize the Graph Builder\n",
    "class ChatState(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(ChatState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a Node that calls an LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def chatbot_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"This node invokes the LLM with the current conversation history.\"\"\"\n",
    "    # The `state.messages` contains the full history, which is passed to the LLM.\n",
    "    response = llm.invoke(state.messages)\n",
    "    # We return a new state object containing only the LLM's latest response.\n",
    "    # `add_messages` will handle appending it to the history.\n",
    "    return ChatState(messages=[response])\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Edges\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compile the Graph\n",
    "chatbot_graph = graph_builder.compile()\n",
    "display(Image(chatbot_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showtime! Launching the Chatbot UI\n",
    "\n",
    "Now we can connect our compiled graph to a Gradio user interface to create a fully functional chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_interface_function(user_input: str, history: list):\n",
    "    \"\"\"The function that Gradio will call on each user interaction.\"\"\"\n",
    "    # The initial state for the graph is just the user's new message.\n",
    "    initial_state = ChatState(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    \n",
    "    # We invoke the graph, which runs the chatbot node.\n",
    "    result = chatbot_graph.invoke(initial_state)\n",
    "    \n",
    "    # The final message from the assistant is returned to the UI.\n",
    "    return result['messages'][-1].content\n",
    "\n",
    "gr.ChatInterface(\n",
    "    chat_interface_function, \n",
    "    title=\"My First LangGraph Chatbot\",\n",
    "    description=\"A simple chatbot built using the 5 core steps of LangGraph.\"\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
