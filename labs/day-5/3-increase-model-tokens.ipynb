{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsMASu-i-JPI"
      },
      "source": [
        "# 📓 Extending an LLM's Context Window\n",
        "\n",
        "1.  **Setup:** Install libraries and ensure a GPU is active.\n",
        "2.  **Load Model:** Load a 4-bit quantized version of Llama 3 8B.\n",
        "3.  **Extend Context:** Apply RoPE scaling on-the-fly during model loading.\n",
        "4.  **Validate:** Test the new context window with a \"Needle in a Haystack\" evaluation and instruct the model to return its findings as JSON."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWvb5eZ2-JPP"
      },
      "source": [
        "---\n",
        "## ⚙️ Step 1: Environment Setup\n",
        "\n",
        "First, we install the necessary libraries from Hugging Face. We also need `bitsandbytes` for quantization, which is the magic that lets us run this large model on a free T4 GPU.\n",
        "\n",
        "*Make sure to enable the T4 GPU runtime by going to **Runtime → Change runtime type → T4 GPU**.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn95HdpO-JPQ",
        "outputId": "68fcac2a-947e-44cc-d1c6-27aae60f8062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Installing required libraries...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Installation Complete!\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install all the necessary libraries\n",
        "# The `-q` flag makes the output less noisy (quiet).\n",
        "\n",
        "print(\"⏳ Installing required libraries...\")\n",
        "!pip install transformers torch accelerate bitsandbytes einops -q\n",
        "\n",
        "print(\"✅ Installation Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjtDdcHi-JPS"
      },
      "source": [
        "---\n",
        "## 🛠️ Step 2: Model Loading and Configuration\n",
        "\n",
        "### Hugging Face Login\n",
        "To access Llama 3, you need a Hugging Face account.\n",
        "1.  Go to the [Meta Llama 3 8B Instruct model page](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) and accept the license terms.\n",
        "2.  Get an access token from your Hugging Face profile: **Settings → Access Tokens**.\n",
        "\n",
        "The cell below will prompt you to paste your token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "a4e4f36431404cd8973d49e9d972988d",
            "1dc68efd38e14e05b3ff8d329065cef6",
            "87dac8f41d68402a8fb5edd5bf0bf1ef",
            "a7f24235eb0947fba8fc60baa039ad0a",
            "fba6fac927f14df6a707020c500ec776",
            "1545eea95b3348bfb67f6668a638eb92",
            "30864ead9a0f40d795bdda212d950259",
            "b0ed7afa3b414d77ae05ed14e6795476",
            "c93c4767766d48cfae502d731f24bd59",
            "e5d86e08050d4eacbd164ca648d29539",
            "80e95a629e40472f84645bb4d8458b6e",
            "93fbc730a3e94864bf2db48fb524bc68",
            "3f0bf0284dc34470ad70458fe69aaaac",
            "34ce9ed39659434f8e96c6fd0f2229d1",
            "d16fdb997b4c44879e9a79c80ebeee25",
            "91f2abcd9feb4ae08c80460794579e4a",
            "3bf52498e1474c2899387e4e8c799e34",
            "1f836564d443445b960d34ef833c6950",
            "e3577394034c41db8510f38227e66af5",
            "8a516ff3c8704e57a9ab263d3c1a35a8"
          ]
        },
        "id": "MDbNiyrA-JPT",
        "outputId": "37c7556f-3a25-4d00-8dbe-e04fe8ba8806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 Please log in to your Hugging Face account.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4e4f36431404cd8973d49e9d972988d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# You'll need a Hugging Face account and an access token.\n",
        "from huggingface_hub import login\n",
        "\n",
        "print(\"🔑 Please log in to your Hugging Face account.\")\n",
        "login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BelwaiRW-JPT"
      },
      "source": [
        "### Quantization and Model Definition\n",
        "\n",
        "To make this powerful model fit onto the Colab T4 GPU (~15 GB VRAM), we'll use **4-bit quantization**. This shrinks the model's memory footprint with a minimal impact on its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i1Q5Q-H-JPU",
        "outputId": "6b514b4e-dd5f-44ce-d18d-fa2360d42c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuration is ready.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# The specific model we'll use\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# Configure our 4-bit quantization to save memory\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, # Enable 4-bit loading\n",
        "    bnb_4bit_quant_type=\"nf4\", # Use the \"nf4\" format for weights\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 # Set the compute dtype for better performance\n",
        ")\n",
        "\n",
        "print(\"✅ Configuration is ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkI90zoz-JPV"
      },
      "source": [
        "---\n",
        "## 🧠 Step 3: Extend Context with RoPE Scaling\n",
        "\n",
        "This is the core of our experiment. We will instruct the `transformers` library to dynamically adjust the model's **Rotary Position Embeddings (RoPE)**.\n",
        "\n",
        "By setting `factor=4.0`, we \"stretch\" the model's original 8,192 token positional understanding to handle approximately **32,768 tokens**. This is done directly when we load the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lhyU9gZ-JPW"
      },
      "outputs": [],
      "source": [
        "# Load the model, applying our quantization config and RoPE scaling simultaneously.\n",
        "# The `device_map=\"auto\"` argument will automatically place the model on the GPU.\n",
        "\n",
        "print(\"⏳ Loading the model... (This may take a few minutes)\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config,\n",
        "    rope_scaling={\"type\": \"linear\", \"factor\": 4.0} # ✨ This is the key line!\n",
        ")\n",
        "\n",
        "# Load the tokenizer associated with the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "print(\"✅ Model and tokenizer loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HKUL3CZ-JPX"
      },
      "source": [
        "---\n",
        "## 🎯 Step 4: Validate\n",
        "\n",
        "A bigger context window is only useful if the model can actually **use** it. We'll test this by:\n",
        "1.  Creating a very long, repetitive text.\n",
        "2.  Placing a unique sentence with a specific fact deep inside it.\n",
        "3.  Asking the model a question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iq1zEAL-JPX"
      },
      "source": [
        "### Create the Test Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej212KTh-JPY"
      },
      "outputs": [],
      "source": [
        "# 1. Define the needle: the specific fact we want the model to find.\n",
        "needle = \"The best way to learn AI is by building hands-on projects.\"\n",
        "\n",
        "# 2. Create a long haystack of repetitive text.\n",
        "haystack = \"The quick brown fox jumps over the lazy dog. This sentence is repeated to create a long context. \" * 2000\n",
        "\n",
        "# 3. Place the needle in the middle of the haystack.\n",
        "text_to_test = haystack + \"\\n\" + needle + \"\\n\" + haystack\n",
        "\n",
        "# Check how many tokens our test text has.\n",
        "input_tokens = tokenizer(text_to_test, return_tensors=\"pt\")\n",
        "print(f\"Total tokens in the 'haystack' text: {input_tokens.input_ids.shape[1]}\")\n",
        "\n",
        "# 4. Create the final prompt for the model, instructing it to return JSON.\n",
        "prompt = f\"\"\"\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "You are an expert information extraction assistant. You will be given a long text and a question. Your task is to find the answer within the text and return it in a structured JSON format.\n",
        "\n",
        "Your JSON output must contain the following keys:\n",
        "- \"retrieved_fact\": The exact sentence you found that answers the question.\n",
        "- \"source_verified\": A boolean value, true if you found the answer in the text.\n",
        "- \"confidence_score\": A float between 0.0 and 1.0 representing your confidence.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Here is the text:\n",
        "---\n",
        "Text: {text_to_test}\n",
        "---\n",
        "Question: Based on the text provided, what is the best way to learn AI?\n",
        "\n",
        "Please provide your answer in the specified JSON format.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the complete prompt and send it to the GPU\n",
        "final_inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "print(\"✅ JSON-instructed prompt is ready and tokenized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfCup-Qf-JPZ"
      },
      "source": [
        "### Generate and Parse the JSON Answer\n",
        "\n",
        "Now we run the model, extract the text response, and parse it into a Python dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBdx7wGq-JPZ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pprint\n",
        "\n",
        "print(\"⏳ Generating the answer...\")\n",
        "\n",
        "# Generate the output from the model\n",
        "outputs = model.generate(\n",
        "    final_inputs.input_ids,\n",
        "    max_new_tokens=150,  # Increase max tokens to ensure the full JSON object is generated\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    do_sample=True,\n",
        "    temperature=0.1, # Lower temperature for more predictable, structured output\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "# Decode the generated tokens into text\n",
        "response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Clean up the output to isolate the assistant's JSON response\n",
        "try:\n",
        "    # Find the start of the assistant's message\n",
        "    json_part_str = response_text.split(\"<|end_header_id|>assistant<|end_header_id|>\")[1].strip()\n",
        "    # Find the start and end of the JSON object\n",
        "    json_start = json_part_str.find('{')\n",
        "    json_end = json_part_str.rfind('}') + 1\n",
        "    json_string = json_part_str[json_start:json_end]\n",
        "\n",
        "    # Parse the string into a Python dictionary\n",
        "    parsed_json = json.loads(json_string)\n",
        "\n",
        "    print(\"\\n--- ✅ Successfully Parsed JSON Output ---\")\n",
        "    pprint.pprint(parsed_json)\n",
        "    print(\"-----------------------------------------\")\n",
        "\n",
        "except (json.JSONDecodeError, IndexError) as e:\n",
        "    print(\"\\n--- ❌ Failed to parse JSON ---\")\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Raw model output:\")\n",
        "    print(response_text.split(\"<|end_header_id|>assistant<|end_header_id|>\")[1].strip())\n",
        "    print(\"-----------------------------\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4e4f36431404cd8973d49e9d972988d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_30864ead9a0f40d795bdda212d950259"
          }
        },
        "1dc68efd38e14e05b3ff8d329065cef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0ed7afa3b414d77ae05ed14e6795476",
            "placeholder": "​",
            "style": "IPY_MODEL_c93c4767766d48cfae502d731f24bd59",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "87dac8f41d68402a8fb5edd5bf0bf1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e5d86e08050d4eacbd164ca648d29539",
            "placeholder": "​",
            "style": "IPY_MODEL_80e95a629e40472f84645bb4d8458b6e",
            "value": ""
          }
        },
        "a7f24235eb0947fba8fc60baa039ad0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_93fbc730a3e94864bf2db48fb524bc68",
            "style": "IPY_MODEL_3f0bf0284dc34470ad70458fe69aaaac",
            "value": false
          }
        },
        "fba6fac927f14df6a707020c500ec776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_34ce9ed39659434f8e96c6fd0f2229d1",
            "style": "IPY_MODEL_d16fdb997b4c44879e9a79c80ebeee25",
            "tooltip": ""
          }
        },
        "1545eea95b3348bfb67f6668a638eb92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91f2abcd9feb4ae08c80460794579e4a",
            "placeholder": "​",
            "style": "IPY_MODEL_3bf52498e1474c2899387e4e8c799e34",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "30864ead9a0f40d795bdda212d950259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "b0ed7afa3b414d77ae05ed14e6795476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93c4767766d48cfae502d731f24bd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5d86e08050d4eacbd164ca648d29539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80e95a629e40472f84645bb4d8458b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93fbc730a3e94864bf2db48fb524bc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f0bf0284dc34470ad70458fe69aaaac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34ce9ed39659434f8e96c6fd0f2229d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d16fdb997b4c44879e9a79c80ebeee25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "91f2abcd9feb4ae08c80460794579e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf52498e1474c2899387e4e8c799e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f836564d443445b960d34ef833c6950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3577394034c41db8510f38227e66af5",
            "placeholder": "​",
            "style": "IPY_MODEL_8a516ff3c8704e57a9ab263d3c1a35a8",
            "value": "Connecting..."
          }
        },
        "e3577394034c41db8510f38227e66af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a516ff3c8704e57a9ab263d3c1a35a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}