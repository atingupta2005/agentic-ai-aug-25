{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81920b31",
   "metadata": {},
   "source": [
    "# 🏗️ Lab: Deploying an AI Agent for Financial Report Insights\n",
    "\n",
    "This hands-on guide walks you through building, containerizing, and deploying an AI agent that:\n",
    "\n",
    "1. Ingests PDF financial reports  \n",
    "2. Extracts key metrics (Revenue, EBITDA, Net Income, etc.)  \n",
    "3. Generates narrative insights using an LLM  \n",
    "4. Exposes a REST API for integration  \n",
    "\n",
    "---\n",
    "\n",
    "## Lab Objectives\n",
    "\n",
    "- Set up a Python environment with necessary libraries  \n",
    "- Implement tools for PDF parsing and metric extraction  \n",
    "- Create an LLM-driven “Insight Generator” tool  \n",
    "- Assemble a LangChain agent that orchestrates parsing, extraction, and insight generation  \n",
    "- Wrap the agent behind a FastAPI service  \n",
    "- Containerize with Docker and test deployment  \n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+  \n",
    "- `pip` package manager  \n",
    "- Docker (for containerization)  \n",
    "- An OpenAI API key (export as `OPENAI_API_KEY`)  \n",
    "- Sample financial report PDFs (place in `./reports/`)  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "1. Clone or create your project folder:\n",
    "   ```bash\n",
    "   mkdir finance_agent && cd finance_agent\n",
    "   ```\n",
    "\n",
    "2. Create a virtual environment and activate it:\n",
    "   ```bash\n",
    "   python -m venv venv\n",
    "   source venv/bin/activate       # macOS/Linux\n",
    "   venv\\Scripts\\activate          # Windows\n",
    "   ```\n",
    "\n",
    "3. Install required packages:\n",
    "   ```bash\n",
    "   pip install langchain openai fastapi uvicorn pdfplumber pandas python-dotenv\n",
    "   ```\n",
    "\n",
    "4. Create a `.env` file with your OpenAI key:\n",
    "   ```\n",
    "   OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXX\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. PDF Parsing & Metric Extraction Tool\n",
    "\n",
    "We’ll use pdfplumber to extract tables and text, and pandas to process tables.\n",
    "\n",
    "### 2.1. Create `tools/pdf_parser.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def parse_financial_pdf(path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts numerical tables and key text passages from a PDF financial report.\n",
    "    Returns a dict with table DataFrames and raw text.\n",
    "    \"\"\"\n",
    "    tables, text = [], \"\"\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "            for table in page.extract_tables():\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                tables.append(df)\n",
    "    return {\"text\": text, \"tables\": tables}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f10d8f",
   "metadata": {},
   "source": [
    "### 2.2. Create `tools/metric_extractor.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2713c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def extract_metrics(tables: List[pd.DataFrame]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Scans DataFrames for common financial metrics (Revenue, EBITDA, Net Income).\n",
    "    Returns a dict of metric names and values.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    keywords = {\n",
    "        \"Revenue\": [\"Revenue\", \"Total Revenue\", \"Net Sales\"],\n",
    "        \"EBITDA\": [\"EBITDA\", \"Earnings Before Interest\"],\n",
    "        \"Net Income\": [\"Net Income\", \"Profit After Tax\"]\n",
    "    }\n",
    "    for df in tables:\n",
    "        for metric, keys in keywords.items():\n",
    "            for key in keys:\n",
    "                mask = df.iloc[:, 0].str.contains(key, case=False, na=False)\n",
    "                if mask.any():\n",
    "                    # Assume last column holds the most recent figure\n",
    "                    val = df.loc[mask, df.columns[-1]].values[0]\n",
    "                    try:\n",
    "                        metrics[metric] = float(val.replace(\",\", \"\"))\n",
    "                    except:\n",
    "                        pass\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e6272",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Insight Generation Tool\n",
    "\n",
    "Wrap the LLM call to generate a CFO-style narrative from the extracted metrics.\n",
    "\n",
    "### 3.1. Create `tools/insight_generator.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0.3,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "def generate_insights(metrics: dict) -> str:\n",
    "    \"\"\"\n",
    "    Given a dict of financial metrics, returns a narrative summary.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a corporate finance expert. Analyze the following key metrics and write a concise executive summary:\n",
    "    {metrics}\n",
    "\n",
    "    Focus on trends, significant changes, and possible drivers.\n",
    "    \"\"\"\n",
    "    response = llm(prompt)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5af8d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Assemble the LangChain Agent\n",
    "\n",
    "Create an agent that chains PDF parsing, metric extraction, and insight generation.\n",
    "\n",
    "### 4.1. Create `agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import Tool, LLMChain\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from tools.pdf_parser import parse_financial_pdf\n",
    "from tools.metric_extractor import extract_metrics\n",
    "from tools.insight_generator import generate_insights\n",
    "\n",
    "# Wrap each function as a Tool\n",
    "pdf_tool = Tool(\n",
    "    name=\"parse_pdf\",\n",
    "    func=parse_financial_pdf,\n",
    "    description=\"Parse a financial PDF and return raw text and tables.\"\n",
    ")\n",
    "metric_tool = Tool(\n",
    "    name=\"extract_metrics\",\n",
    "    func=extract_metrics,\n",
    "    description=\"Extract Revenue, EBITDA, and Net Income from tables.\"\n",
    ")\n",
    "insight_tool = Tool(\n",
    "    name=\"generate_insights\",\n",
    "    func=generate_insights,\n",
    "    description=\"Generate narrative insights from extracted metrics.\"\n",
    ")\n",
    "\n",
    "tools = [pdf_tool, metric_tool, insight_tool]\n",
    "\n",
    "# Initialize a zero-shot agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def analyze_report(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Runs the agent on the given PDF path to return insights.\n",
    "    \"\"\"\n",
    "    # Step 1: parse PDF\n",
    "    parsed = pdf_tool.run(path)\n",
    "    # Step 2: extract metrics\n",
    "    metrics = metric_tool.run(parsed[\"tables\"])\n",
    "    # Step 3: generate narrative\n",
    "    insights = insight_tool.run(metrics)\n",
    "    return insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca03326",
   "metadata": {},
   "source": [
    "### 4.2. Test Locally\n",
    "\n",
    "Add a `__main__` block to `agent.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    report_path = \"./reports/Q1_2025_Financials.pdf\"\n",
    "    summary = analyze_report(report_path)\n",
    "    print(\"\\n=== Executive Summary ===\\n\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77859068",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7890f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python agent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f61765b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Expose as a FastAPI Service\n",
    "\n",
    "Wrap the agent in a REST API to accept PDF uploads or file paths.\n",
    "\n",
    "### 5.1. Create `app.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90850b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI, UploadFile, File\n",
    "from agent import analyze_report\n",
    "import shutil\n",
    "\n",
    "app = FastAPI(title=\"Financial Insights Agent\")\n",
    "\n",
    "@app.post(\"/analyze/\")\n",
    "async def analyze(file: UploadFile = File(...)):\n",
    "    # Save uploaded PDF\n",
    "    path = f\"./temp/{file.filename}\"\n",
    "    with open(path, \"wb\") as buffer:\n",
    "        shutil.copyfileobj(file.file, buffer)\n",
    "    # Run analysis\n",
    "    summary = analyze_report(path)\n",
    "    return {\"filename\": file.filename, \"summary\": summary}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f44d3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 5.2. Test the API\n",
    "\n",
    "From another terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f481dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -X POST \"http://localhost:8000/analyze/\" \\\n",
    "  -H \"Content-Type: multipart/form-data\" \\\n",
    "  -F \"file=@./reports/Q1_2025_Financials.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f70f76",
   "metadata": {},
   "source": [
    "You should receive a JSON response with your narrative summary.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Containerize with Docker\n",
    "\n",
    "### 6.1. Create `Dockerfile`\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "### 6.2. Build & Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Freeze dependencies\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "# Build Docker image\n",
    "docker build -t finance-insights-agent .\n",
    "\n",
    "# Run container\n",
    "docker run -d -p 8000:8000 --name fin-agent finance-insights-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b69fe",
   "metadata": {},
   "source": [
    "Test with the same `curl` command against `localhost:8000`.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Deployment Strategies\n",
    "\n",
    "- **Cloud Run / AWS Fargate:** Deploy the Docker image as a serverless container.  \n",
    "- **Kubernetes:** Create a Deployment and Service; use an Ingress for external access.  \n",
    "- **Monitoring:** Integrate Prometheus/Grafana to track request latency, error rates.  \n",
    "- **Logging:** Ensure FastAPI logs are shipped to ELK or Splunk for audit trails.  \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
